
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Image Captioning Using Neural Network (CNN &amp; LSTM)</title>
    <meta name="description" content="">

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="shortcut icon" href="../favicon.ico">

    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400">
    <link rel="stylesheet" type="text/css" href="../assets/css/screen.css?v=54a8fda773">


    <link rel="canonical" href="http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/amp/">
    
    <meta property="og:site_name" content="Zhenguo Chen">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Image Captioning Using Neural Network (CNN &amp; LSTM)">
    <meta property="og:description" content="In this blog, I will present a image captioning model, which generate a realistic caption for an input image. To help understand this topic, here are examples:             A man on a bicycle down a dirt road.                a dog is running through the grass .    These two images are random images downloaded">
    <meta property="og:url" content="http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/">
    <meta property="og:image" content="http://localhost:2368/content/images/2017/05/sea.jpeg">
    <meta property="article:published_time" content="2017-05-16T17:14:50.000Z">
    <meta property="article:modified_time" content="2017-05-17T17:02:40.000Z">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Image Captioning Using Neural Network (CNN &amp; LSTM)">
    <meta name="twitter:description" content="In this blog, I will present a image captioning model, which generate a realistic caption for an input image. To help understand this topic, here are examples:             A man on a bicycle down a dirt road.                a dog is running through the grass .    These two images are random images downloaded">
    <meta name="twitter:url" content="http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/">
    <meta name="twitter:image" content="http://localhost:2368/content/images/2017/05/sea.jpeg">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Zhenguo Chen">
    <meta property="og:image:width" content="1920">
    <meta property="og:image:height" content="1200">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Zhenguo Chen",
        "logo": "http://localhost:2368/ghost/img/ghosticon.jpg"
    },
    "author": {
        "@type": "Person",
        "name": "Zhenguo Chen",
        "url": "http://localhost:2368/author/zhenguo/",
        "sameAs": []
    },
    "headline": "Image Captioning Using Neural Network (CNN &amp; LSTM)",
    "url": "http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/",
    "datePublished": "2017-05-16T17:14:50.000Z",
    "dateModified": "2017-05-17T17:02:40.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:2368/content/images/2017/05/sea.jpeg",
        "width": 1920,
        "height": 1200
    },
    "description": "In this blog, I will present a image captioning model, which generate a realistic caption for an input image. To help understand this topic, here are examples:             A man on a bicycle down a dirt road.                a dog is running through the grass .    These two images are random images downloaded",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368"
    }
}
    </script>

    <meta name="generator" content="Ghost 0.11">
    <link rel="alternate" type="application/rss+xml" title="Zhenguo Chen" href="http://localhost:2368/rss/">
</head>
<body class="post-template nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="index.html#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
            <li class="nav-home"><a href="http://localhost:2368/">Home</a></li>
    </ul>
        <a class="subscribe-button icon-feed" href="http://localhost:2368/rss/">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        


<header class="main-header post-head " style="background-image: url(../content/images/2017/05/sea.jpeg)">
    <nav class="main-nav overlay clearfix">
        
            <a class="menu-button icon-menu" href="index.html#"><span class="word">Menu</span></a>
    </nav>
</header>

<main class="content" role="main">
    <article class="post">

        <header class="post-header">
            <h1 class="post-title">Image Captioning Using Neural Network (CNN &amp; LSTM)</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2017-05-16">16 May 2017</time> 
            </section>
        </header>

        <section class="post-content">
            <p>In this blog, I will present a image captioning model, which generate a realistic caption for an input image. To help understand this topic, here are examples:</p>

<figure>  
    <img src="../content/images/2017/05/image10.jpg" width="400" align="center">
    <figcaption align="center">A man on a bicycle down a dirt road.</figcaption>
</figure>  

<figure>  
    <img src="../content/images/2017/05/image1.jpg" width="400">
    <figcaption align="center">a dog is running through the grass .</figcaption>
</figure>  

<p>These two images are random images downloaded from internet, but our model can still generate realistic caption for the image. Our model is trying to understand the objects in the scene and generate a human readable caption. For our baseline, we use <a href="http://cvcl.mit.edu/Papers/OlivaTorralbaPBR2006.pdf">GIST</a> for feature extraction, and KNN (K Nearest Neighbors) for captioning. For our final model, we built our model using <a href="https://keras.io/">Keras</a>, and use <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/">VGG</a> (Visual Geometry Group) neural network for feature extraction, <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM</a> for captioning. Our code with a writeup are available on <a href="https://github.com/ZhenguoChen/csci5622Project">Github</a>. Also, we have a short video on <a href="https://www.youtube.com/watch?v=f2waevH1b6I">YouTube</a>.</p>

<h2 id="howthisworks">How this works</h2>

<ul>
<li>Feature extraction</li>
<li>Train a captioning model</li>
<li>Generate a caption from through model</li>
</ul>

<p>To train a image captioning model, we use the <a href="http://shannon.cs.illinois.edu/DenotationGraph/">Flickr30K</a> dataset, which contains 30k images along with five captions for each image. And we extract features from the images and save these them as numpy array. Then we feed the features into captioning model and get the model trained. Given a new image, we first do a feature extraction, then we feed the features into trained model and get prediction. Quite straightforward, right? <br>
<img src="../content/images/2017/05/captioning-model.jpg" alt="captioning process"></p>

<h2 id="baselinegistknn">Baseline: GIST &amp; KNN</h2>

<p>For our baseline, we use GIST to present the images as their features which is array with length 4096. Then we fed these features into KNN model (use ball tree in sklearn):  </p>

<pre><code>    # read image
    img = Image.open('./data/Flicker8k_Dataset/'+im_name)
    # convert to array
    img = np.asarray(img)
    # get descriptor (features)
    desc = gist.extract(img)
</code></pre>

<pre><code>    # trains includes features and captions of images
    knn = BallTree(trains['feats'])
</code></pre>

<p>The training part is quite simple! Then we are going to do prediction. To get the prediction for test image A, we use GIST to extract features A' from A.  And we use BallTree to find the K nearest neighbors of A' from which we get all the candidate captions. The last step is deciding which caption we are going to use. Here, we make the decision according to <a href="https://arxiv.org/abs/1505.04467">consensus</a>. We use BLEU score in nltk to measure the similarity between two captions, then we choose the caption which maximize the following formula:</p>

<p><img src="../content/images/2017/05/Screen-Shot-2017-05-17-at-10.51.55-AM.png" alt="consensus">
Then we get our prediction! Simple enough! Let's look at something more complicated.</p>

<h2 id="finalmodelvgglstmkeras">Final Model: VGG &amp; LSTM (Keras)</h2>

<p>For our final, we built our model using Keras, which is a simple wrapper for implementing the building blocks of advanced machine learning algorithms. To achieve higher performance, we also use GPU. Here is the instruction of <a href="https://keras.io/#installation">install</a> Keras with GPU and use Tensorflow as backend.</p>

<h3 id="featureextractionvgg1619">Feature extraction: VGG16/19</h3>
            <div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9&appId=819156208247732";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
			<div class="fb-comments" data-href="https://zhenguochen.github.io/image-captioning-using-neural-network-cnn-lstm/" data-numposts="10"></div>
        </section>

        <footer class="post-footer">



            <section class="author">
                <h4><a href="../author/zhenguo/">Zhenguo Chen</a></h4>

                    <p>Read <a href="../author/zhenguo/">more posts</a> by this author.</p>
                <div class="author-meta">
                    
                    
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/intent/tweet?text=Image%20Captioning%20Using%20Neural%20Network%20(CNN%20%26%20LSTM)&amp;url=http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://localhost:2368/image-captioning-using-neural-network-cnn-lstm/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>


        </footer>

    </article>
</main>

<aside class="read-next">
    <a class="read-next-story prev no-cover" href="../welcome-to-ghost/">
        <section class="post">
            <h2>Welcome to Ghost</h2>
            <p>You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you…</p>
        </section>
    </a>
</aside>



        <footer class="site-footer clearfix">
            <section class="copyright"><a href="http://localhost:2368">Zhenguo Chen</a> © 2017</section>
            <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
        </footer>

    </div>

    <script type="text/javascript" src="http://code.jquery.com/jquery-1.12.0.min.js"></script>
    
    <script type="text/javascript" src="../assets/js/jquery.fitvids.js?v=54a8fda773"></script>
    <script type="text/javascript" src="../assets/js/index.js?v=54a8fda773"></script>

</body>
